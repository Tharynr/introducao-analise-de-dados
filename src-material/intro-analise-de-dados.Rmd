# Introdução

A análise de dados é uma das atividades mais interessantes da atualidade, com ela é possível monitorar o governo, por exemplo, [operacao serenata](https://serenata.ai/), fazer empresas de sucesso e produtos que atendam a real necessidade de seus clientes, e o mais importante, comprovar a veracidade da informação recebida e saciar nossa curiosidade.
Isto porque com a quantidade de dados disponível, podemos literalmente, saber sobre tudo, aplicando técnicas de análise de dados.
Portando, esse mini-curso tem como objetivo apresentar, de forma introdutória, às principais tecnologias para análise de dados com as linguagens de programação R e Python.


## Dados

Muito foi dito sobre dados, que estes são abundantes e estão em constante crescimento, porém, o que são dados ? 

Bem esta pergunta possui diversas respostas, isto porque há várias definições para dados, aqui iremos assumir que dados são "Qualquer coisa registrada com o propósito de posteriormente ser analisado" - Rafael Santos.

Agora que sabemos a definição de dados, podemos concluir que *Big Data* é um alto volume de dados. Não entraremos no mérito do que é ou não considerado *Big data*, caso queiram ler mais sobre o assunto, recomendamos o livro **Analyzing the Analyzers** publicado pela **O'REILLY**. tabela \@ref(tab:basic-data-types)).

Table: (\#tab:basic-data-types) Types of variables encountered in typical data visualization scenarios.

características mensuráveis que assumem valores em 
uma escala contínua (na reta real), para as quais 
valores fracionais fazem sentido. Usualmente devem 
ser medidas através de algum instrumento. 
Exemplos: peso (balança), altura (régua), 
tempo (relógio), pressão arterial, idade. 

---------------------------------------------------------------------------------------------------------------------
Tipo variável               Exemplos              Escala apropriada       Descrição
------------------------ --------------------- ----------------------- ----------------------------------------------
Quantitativa/númerica    1.3, 5.7, 83,         Contínuas               Valores mensuráveis que assumem valores  
contínua                 1.5x10^-2^                                    em um escala contínua (na reta real).
                                                                       Usualmente devem ser medida através de 
                                                                       algum instrumento. Exemplo:peso(balança)
                                                                       tempo(relógio), pressão arterial.
                                                                               
Quantitativa/númerica    1, 2, 3, 4             Discretas               Características mensuráveis que podem
discreta                                                               assumir apenas um número finito ou
                                                                       infinito contável de valores e, assim,
                                                                       somente fazem sentido valores inteiros.                                                                         Geralmente são o resultado de contagens.
                                                                       Exemplos: número de filhos, número de                                                                           bactérias por litro de leite, número
                                                                       de cigarros fumados por dia.
 
Quantitativa/categóricas  Cachorro, peixe      Discreto                Não possui ordenação dentre as 
nominais                                                               categorias. Essas variáveis são
                                                                       também chamadas de *factors*. Exemplo:
                                                                       Sexo, cor dos olhos, doente/sadio
                                                                       
Quantitativa/categóricas  Janeiro, Fevereiro   Discreto                Existe uma ordenação entre as categorias.
ordinais                                                               Essas variáveis são também chamadas de 
                                                                       *ordered factors*. Exemplo: escolaridade
                                                                       (1°, 2°, 3°), mês de observação(janeiro,
                                                                       fevereiro... dezembro).

Data ou tempo            Jan. 5 2018, 8:03am    Contínuo ou Discreto    Dia ou hora específicos. Também datas 
                                                                       genéricas, Por exemplo 29 de Fevereiro em
                                                                       anos não bissextos
                                                                       
Texto                    The quick brown fox   Nenhum, ou discreto     Texto normal e pode ser tratado
                         jumps over the lazy                           como categórico se precisar.
                         dog.
---------------------------------------------------------------------------------------------------------------------

### Formatos de dados

Como já citado, existem muitos dados disponíveis, estes vindos das mais diversas fontes e formatos, e boa parte dos desafios na análise de dados está vinculada ao formato com que o dados está disponível, isto porque dependendo do formato, existem etapas de organização que devem ser aplicada nos dados.

Nos subtópicos abaixo, serão descritos os principais formatos de dados e alguns exemplos de cada um destes.

#### Dados estruturados
Dado estrutura é o sonho de quaisquer ciêntista de dados, 

#### Dados semi-estruturados

#### Dados não estruturados

## O que é análise de dados

Para *John W. Tukey*, grande parte da análise de dados é inferencial, ou seja, o ato de extrair informações de uma amostra em relação ao conjunto todo. É interessante ressaltar, que análise de dados não é conceito novo, por exemplo, essa definição de *John* foi publicada em 1961, no artigo *The Future of Data Analysis*.

> Inferência estatística é um ramo da Estatística cujo objetivo é fazer afirmações a partir de um conjunto de valores representativo (amostra) sobre um universo (população). - Wikipedia

Buscando por mais definições, a [Wikipedia](https://en.wikipedia.org/wiki/Data_analysis) descreve como análise de dados como o processo de observação, limpeza, transformação e modelagem de dados. Com o objetivo de extrar informações de dados não tratados.

Artigo públicado pelo [dataquest](https://www.dataquest.io/blog/data-analyst-data-scientist-data-engineer/), contém uma abordagem muito interessante, com o foco no mercado, ele define o analista de dados como um agregador de valor para a companhia através de perguntas e respostas obtidas através do dados, dessa forma, ajudando na tomada de decisão da empresa. Atividades comuns feitas pelo analista de dados incluem a limpeza do dado, análise de perfomance e visualização de dados. 

As principais tarefas de uma analista, segundo o artigo do dataquest, são:

- Limpeza e organização de dados;
- Uso de estatística para ter uma visão geral dos dados;
- Análise de tendencias encontradas no dado;
- Criação de visualização e *dashboards* para ajudar a interpretação e tomada de decisão da empresa;
- Apresentação dos resultados da análise técnica para clientes ou times internos.

Resumindo essas tarefas, o análista deve possuir habilidades de limpeza, minipulação e visualização dos dados, entender do négocio, e saber rransferir a informações gerada de suas análises para diferentes clientes.


### Processos da análise de dados

Agora que sabemos o que faz um analista de dados, vamos descrever brevemente, no que consiste cada processo. Vamos trazer uma definição feita pela Hadley para deixar um pouco mais lucidativo. 

> Cada processo é abordado com detalhes em R e Python.

![](./images/data-science.png)

Primeiro, é importante **importar** o dado, ou seja, realizar a leitura do dado, sendo ele  `.csv, .kml, .json` e qualquer outro formato. Assim que o dado for importado, é importante deixá-lo limpo ou **tidy**, para Hadley, um dado organizado (**tidy**), é quando cada coluna é uma variável, e cada linha é um observação. Por exemplo, em R (ref:tidy_data):

```{r, fig.cap = '(ref:tidy_data)'}
  library(knitr)
  escola <- data.frame(nome=c("Joao", "Maria","Helena"),
                       idade=c(14, 15, 21),
                       nivel_escolar=c("EF", "EM", "Graduacao" ))
  
  # Idade em anos
  # EF - Ensino fundamental
  # EM - Ensino Médio
  knitr::kable(escola)
```

Sabemos que `Joao` tem `14` anos e está no `ensino fundamental`, seguindo a ideia do **tidy**.

Próximo passo, é a **transformação**, geralmente é a criação de novas varíaveis com base no conjunto de dados, por exemplo, a média da nota dos alunos em certo ano escolar. Nesta etapa, é importante gerar algumas perguntas sobre o seu conjunto e tentar responde-las com a manipulação do dado. Um exemplo de tranformação muito utilizado, é extrair o dia da semana de uma data `x`.Por exemplo, em R (ref:r_date):

```{r,  fig.cap = '(ref:r_date)'}
  suppressMessages(library(lubridate))

  data <- dmy("11/10/2018") 
  wday(data, label = TRUE)
```

No exemplo acima, estamos usando o pacote `lubridate` e com 1 linha de código descobrimos o dia da semana do dia 11 de Outubro.

Hadley descreve a visualização e a modelagem como engenharia de representação de conhecimento. A **visualização**, pode gerar novos conhecimentos, questionamentos e respostas. Segundo [Claus O. Wilke](https://serialmentor.com/dataviz), a visualização de dados ou dataviz, é a parte arte e a parte ciência na área de ciências de dados, logo, a visualização precisa estar correta e agradável para o leitor interpretá-la.   

> TIL: visualisation ou visualization tem o mesmo significado, mas, na Europa é com "s" e na América com "z".







## Diferenças entre análise de dados e ciência de dados

<!--chapter:end:01-intro.Rmd-->

# Introdução ao R `r emo::ji("smile")`

## Definição de variáveis

### Tipos primitivos
```{r}
  a <- 7L
  b = 14.01
  42 -> c
  k <- FALSE
  g <- 12i # tipo complexo*
  couse <- 'cool'
  
  
  # Para ver inspecionar o valor das variáveis
  print(a)
  b
  cat(c)
  
  # Para ver as classes[1]
  class(a)
  class(b)
  class(c)
  class(k)
  class(couse)
  
  # Para remove-las
  rm(a)
  
```

1.2 Tipos de dados estruturados
```{r}
  # Vetores[2]
  vetor_boleano <- c(FALSE, TRUE, TRUE, FALSE)
  vetor_numerico <- c(3.14, 6.28, 2.3)
  vetor_char <- c('ola', 'pessoal', 'xd')
  v01 <- 1:4
  v02 <- 84:76
  v03 <- seq(from=1, to=10)
  v06 <- rep('DATA SCIENCE', 50)
  v08 <- paste("A", 'B', 'C') 
  v11 <- paste0("EX_", 1:5)
  
  # Podemos misturar tudo
  vetor_misturado <- c("sou legal", FALSE, 21)
  # Vetor atomico tem um único tipo, então se misturarmos, vai converter para o tipo mais forte:
  #1 - character
  #2 - complex
  #3 - numeric
  #4 - integerc
  #5- logical
  # Vetor misturado será convertido em qual tipo?
  
  # Conferirndo a variável e tamanho
  is.atomic(vetor_boleano)
  is.list(vetor_boleano)
  length(vetor_boleano)
  
  # Lista
  lista_boleano <- list(FALSE, TRUE, TRUE, FALSE)
  lista_inteiro <- list(12L, 10L, 7L)
  lista_misturada <- list(FALSE, 12L, 't', 2i)
  
  # Conferindo o tamanho da lista
  is.list(lista_boleano)
  is.recursive(lista_boleano)
  is.atomic(lista_boleano)
  is.list(lista_inteiro)
  
  
  # Array
  a <- array(c('green','yellow'),dim = c(3,3,2)); a
  
  class(a)
  typeof(a)
  is.atomic(a)
  # Por que não é um vetor?
  is.vector(a)
  is.list(a)
  
  
  # Matriz
   m2 <- matrix(data = c(1:25, rep("legal", 5)), nrow = 5, ncol=6)
   
   is.matrix(m2)
   is.array(m2)
   
   m2[5,6]

```

1.3 DataFrame

```{r}
   # DataFrame[3]
   data_frame <- data.frame(Risco=c(FALSE,FALSE, FALSE, FALSE,TRUE), Animal=c("Cachorro", "Gato", "Capivara", "Girafa", "Macaco"), Periculosidade=c(200, 400, 0, 7, 1000))
  
  # Para ver o tamanho
  length(data_frame)
  
  # Podemos acessar os valores individuais usando o '$'
  data_frame$Animal
  
  # Acessando os valores por indices
  data_frame[,2]
  data_frame[2,]
  data_frame[3,2]
  
  
  # Visualização das lihas iniciais
  head(data_frame)
  # Visualização das linhas finais
  tail(data_frame)
  
  # Nome das colunas
  colnames(data_frame)
  # Nome das linhas
  rownames(data_frame)
  
  # Quantidade de colunas
  ncol(data_frame)
  # Quantidade de linhas
  nrow(data_frame)
  
  # Podemos observar a estrutura
  str(data_frame)
  
  # Algumas estatísticas básicas 
  summary(data_frame)
```


2. Operações Básicas

2.1 Dicas úteis
```{r, eval=FALSE}
  # Para usar algum pacote
  library(tidyverse)

  # Para procurar por um pacote
  ??ggsom

  # Para instalar algum pacote que esteja no CRAN [4]
  #install.packages("meupacotefavorite")

  # Para ler sobre alguma função
  ?sum()
  
  # Para verificar seu diretório atual
  getwd() 
  
  # Para definir um novo diretório
  setwd("~/R/ggsom/")
  
  # Para ler conjunto de dados
  df <- read.csv2("~/Dados/pesquisa_google_trend/convolutional_neural_networks.csv", 
            header = TRUE, sep = ",")
  
  # Dependendo do tamanho do dataset, vale a pena usar fread() ou read_csv()
```


2.2 Estatisca básica
```{r}
  # Vamos usar o dado do filme Star Wars do pacote dplyr*
  suppressMessages(library(dplyr))
  starwars <- dplyr::starwars
  
  # Desse modo o dataset é carregado no nosso ambiente, use ls()
  data(starwars)
  
  # Vamos visualizar o dado
  dplyr::glimpse(starwars)
  
  # Vamos ver a média de ano de nascimento
  mean(starwars$birth_year)
  
  # oops... - Observe que o NA atrapalha nossa média,vamos remove-lo
  mean(starwars$birth_year, na.rm = TRUE)
  
  
  # Podemos procurar pela menor data de nascimento
  min(starwars$birth_year, na.rm = TRUE)
  
  # Pelo máximo também
  max(starwars$birth_year, na.rm = TRUE)
  
  # Desvio padrão 
  sd(starwars$birth_year, na.rm = TRUE)
```

3. Os ifs da vida...
```{r, eval=FALSE}
  
  if(starwars$name == "Luke Skywalker"){
    "Faz cara de vilão"
  } else {
    "Faz cara de bonzinho"
  }
  # hackezinho rápido
  vilao <- ifelse(starwars$name == "Luke Skywalker",
         TRUE, FALSE)
  
  # Pense em vetor...
  starwars$name[vilao]
  
  # Foreach
  for(i in starwars$name){
    print(i)
  }
  
  # Um For pouco mais rápido[5]
  for(i in seq_along(starwars$name)){
    print(starwars$name[i])
  }
  # Usando map do pacote purr
  library(purrr)
  purrr::map_chr(starwars$name, print)

```

## Para saber mais

[Números complexos - 1](!https://stat.ethz.ch/R-manual/R-devel/library/base/html/complex.html)

[Tipos númericos em R - 2](!http://uc-r.github.io/integer_double/)

[Diferença entre lista e vetor - 3](!https://www.burns-stat.com/documents/tutorials/impatient-r/)

[CRAN - 4](!https://cran.r-project.org/doc/FAQ/R-FAQ.html#Introduction)

[R eficiente - 5](!https://csgillespie.github.io/efficientR/)


## Materias utilizados como base
[Rafael Santos](!https://github.com/rafaeldcsantos/CAP-394)

- José Roberto M. Garcia


 













<!--chapter:end:02-rlang.Rmd-->

# Introdução ao Python `r emo::ji("rocket")`

Python é uma linguagem multiparadigma, com uma sintaxe muito simples que permite ao programador focar no problema e deixar de lado questões da linguagem. 
Esta é uma linguagem amplamente utilizada em diversos áreas, por conta principalmente das milhares de bibliotecas que a linguagem possui, todas elas distribuidas pela comunidade incrível que a linguagem possui `r emo::ji("heart")`

Neste introdução, o foco será a aplicação da linguagem Python na manipulação e tratamento de dados, utilizando como base a biblioteca Pandas.

Você pode estar se perguntando o motivo da utilização desta biblioteca, e a resposta é bem simples, Python é uma linguagem para uso geral, assim, suas funções nativas não tem foco em uma função específica, como ocorre em linguagem como R, que já tem um foco em uma área específica (No caso do R, em análises estatísticas, como descrito no capítulo 2 deste material), assim esta biblioteca facilita o processo de manipulação e tratamento de dados.

No próximo capítulo você verá como realizar a visualização de seus dados utilizando a biblioteca `plotnine`, que é uma implementação do ggplot para o Python.

Vamos começar !

## Introdução ao Pandas `r emo::ji("panda_face")`

Como forma de iniciar, vamos começar entendendo o que é a biblioteca Pandas e qual seu objetivo geral, para isto, vejamos a definição feita pelo próprio site do projeto.

> pandas é uma biblioteca open source, licenciada pelo BSD, que fornece estruturas de dados de alto desempenho e fáceis de usar e ferramentas de análise de dados para a linguagem de programação Python.

Veja então que, tudo o que é necessário para a realização da maioria dos casos de análise de dados utilizando a linguagem Python, irão, bem provavelmente, trabalhar com esta biblioteca.

Para que se tenha uma ideia, o pandas pode ser aplicado em análises envolvendo:

- Finanças;
- Análise estatística;
- Ciência social;
- Além de diversas outras áreas de ciências e engenharia.

Isto tudo, por contar com diversas funções e estruturas de dados que facilitam os processos de análise, por falar nestas funções e estruturas, no próximo tópico, vamos discutir um pouco mais sobre as principais presentes no pandas. 

## Estruturas de dados

As duas principais estruturas de dados presentes no pandas são:

- Series;
- DataFrames.

Nos subtópicos abaixo vamos ver as características de cada uma destas estruturas, e em seguida, veremos alguns utilitários para leitura dos dados com Pandas.

### Series

As `Series` são estruturas de dados unidimensionais, que contam com diversos métodos para a manipulação de dados.
Pode-se entender que as `Series` são estruturas de dados simples, assim como as listas padrões da linguagem Python, com uma pequena diferença, para cada item dentro de uma `Series` tem-se indices, estes podendo ser valores numéricos ou texto.

Vamos começar a utilização, para facilitar o entendimento.

```{r}
# Estes comandos não devem ser executados em seu terminal
library(reticulate) 
use_python("/home/felipe/anaconda3/bin/python")
```

Para iniciar, vamos criar um simples `Series` e colocar dentro de uma variável. Para isto, importando a biblioteca pandas, e passamos para ela o 'apelido' de `pd`.

Em seguida, criar uma `Series` simples, passando como parâmetro de entrada uma lista com três valores, veja:

```{python}
import pandas as pd

s = pd.Series([1, 2, 3]); print(s)
```

É interessante notar que, cada uma das linhas, tem associado um index (Pode ser visto do lado esquerdo dos valores), e isto permite a recuperação dos valores através destes index. Você pode fazer uma analogia a forma com que você recupera os valores em um dicionário em Python, a diferença aqui é que, esta é uma estrutura de dados de alto desempenho, além de que, estas estruturas são otimizadas para fazer a melhor utilização de memória possível.

```{python}
print(s[0]) # Recupera o valor do index com nome 0
```

Por falar em dicionários, estes podem ser facilmente transformados em `Series`, veja:

```{python}
dicto = {
  'faculdade': 'Fatec',
  'nota': 10 
}

dicto_s = pd.Series(dicto); print(dicto_s)
```

Após a conversão, o uso é basicamente o mesmo do dicionário, porém com os benefícios já citados. Além do que já foi dito sobre os `Series`, é importante lembrar que, estas estruturas de dados possuem diversos métodos para facilitar a manipulação e entendimento dos dados, vamos a alguns destes métodos

Caso queira-se uma rápida descrição de seus dados, é possível obter um resumo estatístico

```{python}
data = pd.Series([1, 2, 3, 4, 5])

print(data.describe())
```

Este tipo de comando pode te ajudar a entender os dados que você está analisando.

Além disto, você pode ter necessidades como buscas dentro do conjunto de dados, existem diversas maneiras de fazer isto com pandas, mas uma forma simples e intuitiva é a utilização de indexação booleana, onde basicamente uma expressão lógica é passada como ponto para indexação.

```{python}
data_m_tres = data[data > 3] # Devolve todos os valores dentro da Serie que são maiores que 3
print(data_m_tres)
```

Caso os valores das variáveis sejam string, também é possível realizar buscas, utilizando a mesma técnica.

```{python}
faculdade = dicto_s[dicto_s == 'Fatec'] # Recupera o campo que tem o valor 'Fatec'
print(faculdade)
```

Porém, como citado lá no início deste tutorial, as `Series` são estruturas unidimensionais, o que significa que não poderemos ter matrizes dentro das `Series`, caso tentarmos fazer a inserção de uma matriz, ele irá aceitar, porém, fará o tratamento dos dados como se fossem diveras listas separadas dentro da `Series`, veja:

```{python}
matriz = pd.Series([[1, 2, 3], [4, 5, 6]])
print(matriz)
```

Percebeu ? Para estes casos, faz-se necessário o uso de uma outra estrutura de dados, o DataFrame, que vamos tratar no próximo capítulo.

### Dataframes

Agora que você já conhece como as `Series` funcionam, vamos apresentar a você o `DataFrame`, que difere das `Series` por serem multidimensionais, ou seja, aqui temos matrizes `r emo::ji("rainbow")`

Mas por esta simples diferença, a manipulação dos `DataFrames` acabam sendo diferentes, não nos métodos, que em boa parte dos casos será os mesmos já apresentados, e sim, na maneira de pensar na manipulação, isto porque, trabalhar com multiplas linhas e colunas de uma única vez, pode tornar sua análise diferente.

Além disto, no caso do pandas, boa parte dos métodos de leitura de dados, já retornam por padrão o `DataFrame` (Os métodos de leitura serão explicados mais abaixo).

Vejamos algumas características bacanas dos `DataFrames`

```{python}
matriz = pd.DataFrame([[1, 2, 3], [4, 5, 6]])
print(matriz)
```

Veja que, da mesma forma que as `Series`, os `DataFrames` tem o index que pode ser nomeado, e 
além destes, as colunas também podem ser nomeadas.

```{python}
tabela = pd.DataFrame([[.9, .8, .7], [.4, .5, .7]], columns = ['primeiro', 'segundo', 'terceiro'], index = ['zero', 'um'])
print(tabela)
```

E a recuperação tanto das linhas quanto das colunas pode ser feita utilizando a ideia da recuperação em dicionários de Python, como citado anteriormente.

```{python}
# Recuperando coluna
coluna = tabela['primeiro']
print(coluna)
```

```{python}
# Recuperando linha
linha = tabela.loc['zero']
print(linha)
```

Para a recuperação da linha utilizamos um método do `DataFrame`, o `loc`, este permite recuperar uma linha através de seu nome, porém pode-se também recuperar pela posição, utilizando o método `iloc`.

```{python}
linha_um = tabela.iloc[1]
```

A diferença entre os métodos está justamente no que ele procura, no primeiro, `loc`, busca-se nomes, e no segundo, `iloc`, tenta-se recuperar a posição.

Quando apresentamos as `Series` falamos sobre o método `describe`, ele também está disponível para o `DataFrame`, porém, caso você queira algum parâmetro estatístico específico, é possível chama-lo através de um método do `DataFrame`.

```{python}
print(tabela.mean()) # Média
print(tabela.median()) # Mediana
```

Outros métodos úteis podem ser vistos abaixo

```{python}
print(tabela.max()) # Recupera a coluna com maior valor
print(tabela.min()) # Recupera a coluna com o menor valor
print(tabela.sum()) # Faz o somatório dos valores de cada linha
```

Lembre-se, muitos dos métodos apresentados na seção do `DataFrame` funcionam nas `Series`, e o contrátio também é verdadeiro.

### Funções de leitura e escrita

Além das estruturas de dados poderosas, o pandas também possui funções para leitura e escrita que são **APELONAS**

Para a leitura de csv, podemos utilizar a `read_csv`

```{python}
df = pd.read_csv('data/titanic.csv') # O caminho pode ser diferente eu sua máquina
print(df.head()) # Função que demonstra o início do DataFrame carregado
print(df.tail()) # Função que demonstra o final do DataFrame carregado
```

Caso você esteja trabalhando com alguma API Rest, você pode fazer com que o json seja transportado para um `DataFrame`, veja

```{python}
json_frame = pd.read_json('https://www.reddit.com/r/technology/.json')
print(json_frame.head())
print(json_frame.columns) # Recupera as colunas do DataFrame
```

Da mesma forma que a leitura, a escrita é extremamente fácil. Para salvar um CSV, ou um JSON, basta utilizar os métodos `to_csv` e `to_json`, presentes dentro do `DataFrame`.

```{python}
df.to_csv('nome_do_csv.csv') # Salva o CSV
df.to_json('nome_do_json.json') # Salva o JSON
```

Viu ? É tudo muito simples e direto, o que te permite focar em sua análise, e deixar de lado problemas com sintaxe `r emo::ji("statue_of_liberty")`, mas, após a sua análise, é importante apresentar seus dados, para isto, vamos aprender a utilizar a biblioteca plotnine para fazer **plots** e visualizar seus dados.

Vamos para o próximo capítulo.

<!--chapter:end:03-python.Rmd-->

# Introdução ao ggplot `r emo::ji("bar_chart")`


<!--chapter:end:04-dataviz.Rmd-->

